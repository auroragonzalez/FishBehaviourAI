{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c9d567",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's import all required libraries and check our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fc00aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n",
      "Current working directory: /home/aurorax/Git_repos/FishBehaveAI/notebooks/training\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install roboflow ultralytics pandas numpy matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for custom utilities\n",
    "sys.path.append(str(Path.cwd().parent.parent / 'src'))\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc34a5",
   "metadata": {},
   "source": [
    "## 2. Download Dataset from Roboflow\n",
    "\n",
    "Configure your Roboflow credentials and download the dataset.\n",
    "\n",
    "**âš ï¸ Security Note:** Replace the API key with your own. Consider using environment variables for sensitive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea173c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roboflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mroboflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Roboflow\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Roboflow configuration\u001b[39;00m\n\u001b[32m      4\u001b[39m API_KEY = \u001b[33m\"\u001b[39m\u001b[33mhPG6x1mG5XJR2YgHc6Eo\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# TODO: Replace with your API key or use os.getenv('ROBOFLOW_API_KEY')\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'roboflow'"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# Roboflow configuration\n",
    "API_KEY = \"hPG6x1mG5XJR2YgHc6Eo\"  # TODO: Replace with your API key or use os.getenv('ROBOFLOW_API_KEY')\n",
    "WORKSPACE = \"fishbehaviour\"\n",
    "PROJECT_NAME = \"prova01_train_videouno\"\n",
    "VERSION = 1\n",
    "FORMAT = \"yolov9\"\n",
    "\n",
    "# Initialize Roboflow\n",
    "rf = Roboflow(api_key=API_KEY)\n",
    "print(f\"Connected to Roboflow workspace: {WORKSPACE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abe427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "project = rf.workspace(WORKSPACE).project(PROJECT_NAME)\n",
    "version = project.version(VERSION)\n",
    "dataset = version.download(FORMAT)\n",
    "\n",
    "print(f\"\\nâœ… Dataset downloaded successfully!\")\n",
    "print(f\"Dataset location: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6afc2b",
   "metadata": {},
   "source": [
    "## 3. Explore Dataset Structure\n",
    "\n",
    "Let's examine what we downloaded and validate the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaefa6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Find and load data.yaml\n",
    "data_yaml_path = Path(dataset.location) / \"data.yaml\"\n",
    "\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in data_config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each split\n",
    "def count_files_in_dir(directory, extension='.jpg'):\n",
    "    \"\"\"Count files with specific extension in directory\"\"\"\n",
    "    path = Path(directory)\n",
    "    if path.exists():\n",
    "        return len(list(path.glob(f'*{extension}'))) + len(list(path.glob(f'*.png')))\n",
    "    return 0\n",
    "\n",
    "dataset_path = Path(dataset.location)\n",
    "\n",
    "splits = {\n",
    "    'train': dataset_path / 'train' / 'images',\n",
    "    'valid': dataset_path / 'valid' / 'images',\n",
    "    'test': dataset_path / 'test' / 'images'\n",
    "}\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for split_name, split_path in splits.items():\n",
    "    if split_path.exists():\n",
    "        img_count = count_files_in_dir(split_path)\n",
    "        label_path = split_path.parent / 'labels'\n",
    "        label_count = count_files_in_dir(label_path, '.txt')\n",
    "        print(f\"{split_name.upper():6s}: {img_count} images, {label_count} labels\")\n",
    "    else:\n",
    "        print(f\"{split_name.upper():6s}: Directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375192d",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images\n",
    "\n",
    "Let's visualize some images with their annotations to understand our data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def visualize_sample_with_labels(image_path, label_path, class_names):\n",
    "    \"\"\"Visualize an image with its YOLO format bounding boxes\"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Read labels\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = f.readlines()\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        for label in labels:\n",
    "            parts = label.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                \n",
    "                # Convert YOLO format to pixel coordinates\n",
    "                x = (x_center - width/2) * img_width\n",
    "                y = (y_center - height/2) * img_height\n",
    "                w = width * img_width\n",
    "                h = height * img_height\n",
    "                \n",
    "                # Draw rectangle\n",
    "                rect = patches.Rectangle((x, y), w, h, linewidth=2, \n",
    "                                        edgecolor='lime', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "                # Add label\n",
    "                class_name = class_names.get(class_id, f\"Class {class_id}\")\n",
    "                ax.text(x, y-5, class_name, color='lime', fontsize=10,\n",
    "                       bbox=dict(boxstyle='round', facecolor='black', alpha=0.5))\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Sample: {image_path.name}\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Get class names from data config\n",
    "class_names_list = data_config.get('names', [])\n",
    "class_names = {i: name for i, name in enumerate(class_names_list)}\n",
    "\n",
    "print(f\"Classes in dataset: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 3 random samples from training set\n",
    "train_images_dir = dataset_path / 'train' / 'images'\n",
    "train_labels_dir = dataset_path / 'train' / 'labels'\n",
    "\n",
    "if train_images_dir.exists():\n",
    "    image_files = list(train_images_dir.glob('*.jpg')) + list(train_images_dir.glob('*.png'))\n",
    "    samples = random.sample(image_files, min(3, len(image_files)))\n",
    "    \n",
    "    for img_path in samples:\n",
    "        label_path = train_labels_dir / f\"{img_path.stem}.txt\"\n",
    "        fig = visualize_sample_with_labels(img_path, label_path, class_names)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Training images directory not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a388b",
   "metadata": {},
   "source": [
    "## 5. Configure Training Parameters\n",
    "\n",
    "Set up the training configuration for YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'model': 'yolov9c.pt',  # Pretrained model\n",
    "    'data': str(data_yaml_path),\n",
    "    'epochs': 50,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'patience': 100,\n",
    "    'device': None,  # None = auto-detect GPU/CPU\n",
    "    'project': 'results/training_runs',\n",
    "    'name': 'yolo_fish_behavior',\n",
    "    'exist_ok': False,\n",
    "    'pretrained': True,\n",
    "    'optimizer': 'auto',\n",
    "    'verbose': True,\n",
    "    'seed': 0,\n",
    "    'deterministic': True,\n",
    "    'lr0': 0.01,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'cos_lr': False,\n",
    "    'val': True,\n",
    "    'plots': True,\n",
    "    'save': True\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"{key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc224d02",
   "metadata": {},
   "source": [
    "## 6. Load Model and Start Training\n",
    "\n",
    "Initialize the YOLO model and begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab03110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = YOLO(TRAINING_CONFIG['model'])\n",
    "\n",
    "print(f\"âœ… Model loaded: {TRAINING_CONFIG['model']}\")\n",
    "print(f\"Starting training with {TRAINING_CONFIG['epochs']} epochs...\")\n",
    "print(f\"This may take a while depending on your hardware.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c547623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(\n",
    "    data=TRAINING_CONFIG['data'],\n",
    "    epochs=TRAINING_CONFIG['epochs'],\n",
    "    imgsz=TRAINING_CONFIG['imgsz'],\n",
    "    batch=TRAINING_CONFIG['batch'],\n",
    "    patience=TRAINING_CONFIG['patience'],\n",
    "    device=TRAINING_CONFIG['device'],\n",
    "    project=TRAINING_CONFIG['project'],\n",
    "    name=TRAINING_CONFIG['name'],\n",
    "    exist_ok=TRAINING_CONFIG['exist_ok'],\n",
    "    pretrained=TRAINING_CONFIG['pretrained'],\n",
    "    optimizer=TRAINING_CONFIG['optimizer'],\n",
    "    verbose=TRAINING_CONFIG['verbose'],\n",
    "    seed=TRAINING_CONFIG['seed'],\n",
    "    deterministic=TRAINING_CONFIG['deterministic'],\n",
    "    lr0=TRAINING_CONFIG['lr0'],\n",
    "    lrf=TRAINING_CONFIG['lrf'],\n",
    "    momentum=TRAINING_CONFIG['momentum'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay'],\n",
    "    warmup_epochs=TRAINING_CONFIG['warmup_epochs'],\n",
    "    val=TRAINING_CONFIG['val'],\n",
    "    plots=TRAINING_CONFIG['plots'],\n",
    "    save=TRAINING_CONFIG['save']\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2307a",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance\n",
    "\n",
    "Run validation on the test set and analyze results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2027829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "metrics = model.val(\n",
    "    data=TRAINING_CONFIG['data'],\n",
    "    split='test',  # Use test split\n",
    "    conf=0.5,\n",
    "    save_json=True,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3fd26e",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Results\n",
    "\n",
    "Display training curves and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ec7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load training results\n",
    "results_dir = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name']\n",
    "results_csv = results_dir / 'results.csv'\n",
    "\n",
    "if results_csv.exists():\n",
    "    df_results = pd.read_csv(results_csv)\n",
    "    df_results.columns = df_results.columns.str.strip()  # Clean column names\n",
    "    \n",
    "    # Plot training metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    if 'train/box_loss' in df_results.columns:\n",
    "        axes[0, 0].plot(df_results['epoch'], df_results['train/box_loss'], label='Box Loss')\n",
    "        axes[0, 0].plot(df_results['epoch'], df_results['train/cls_loss'], label='Class Loss')\n",
    "        axes[0, 0].plot(df_results['epoch'], df_results['train/dfl_loss'], label='DFL Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].set_title('Training Losses')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # mAP curves\n",
    "    if 'metrics/mAP50(B)' in df_results.columns:\n",
    "        axes[0, 1].plot(df_results['epoch'], df_results['metrics/mAP50(B)'], label='mAP50')\n",
    "        axes[0, 1].plot(df_results['epoch'], df_results['metrics/mAP50-95(B)'], label='mAP50-95')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mAP')\n",
    "        axes[0, 1].set_title('Validation mAP')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision and Recall\n",
    "    if 'metrics/precision(B)' in df_results.columns:\n",
    "        axes[1, 0].plot(df_results['epoch'], df_results['metrics/precision(B)'], label='Precision')\n",
    "        axes[1, 0].plot(df_results['epoch'], df_results['metrics/recall(B)'], label='Recall')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].set_title('Precision and Recall')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    if 'lr/pg0' in df_results.columns:\n",
    "        axes[1, 1].plot(df_results['epoch'], df_results['lr/pg0'])\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Full results saved in: {results_dir}\")\n",
    "else:\n",
    "    print(f\"Results file not found at: {results_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77ddd0",
   "metadata": {},
   "source": [
    "## 9. Test Inference on Sample Images\n",
    "\n",
    "Run predictions on test images to visualize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e99f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    model_best = YOLO(str(best_model_path))\n",
    "    print(f\"âœ… Loaded best model from: {best_model_path}\")\n",
    "    \n",
    "    # Run inference on test images\n",
    "    test_images_dir = dataset_path / 'test' / 'images'\n",
    "    if test_images_dir.exists():\n",
    "        test_images = list(test_images_dir.glob('*.jpg')) + list(test_images_dir.glob('*.png'))\n",
    "        samples = random.sample(test_images, min(3, len(test_images)))\n",
    "        \n",
    "        for img_path in samples:\n",
    "            # Predict\n",
    "            results = model_best.predict(source=str(img_path), conf=0.5, save=False)\n",
    "            \n",
    "            # Display result\n",
    "            result_plot = results[0].plot()\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(result_plot)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Inference: {img_path.name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"Test images directory not found!\")\n",
    "else:\n",
    "    print(f\"Best model weights not found at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512b0e3",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "**Training Complete!** \n",
    "\n",
    "Model weights saved in: `{results_dir}/weights/`\n",
    "- `best.pt`: Best model based on validation metrics\n",
    "- `last.pt`: Final epoch model\n",
    "\n",
    "**Next Steps:**\n",
    "1. Analyze confusion matrix in the results directory\n",
    "2. Export model for deployment if needed\n",
    "3. Run behavioral analysis on tracked fish\n",
    "4. Create Markov chain analysis from predictions\n",
    "\n",
    "**Files Generated:**\n",
    "- Training results and plots in `results/training_runs/`\n",
    "- Model weights in `weights/` subdirectory\n",
    "- Validation predictions and metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
